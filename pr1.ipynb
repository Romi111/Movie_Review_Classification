{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# K-Nearest Neighbor - Movie Review Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#read input file\n",
    "train_data = open(\"/home/ss/CMPE-255-Fa17/pr/train.dat\",\"r\")\n",
    "ts = train_data.readlines()\n",
    "\n",
    "test_data = open(\"/home/ss/CMPE-255-Fa17/pr/test.dat\",\"r\")\n",
    "ts1 = test_data.readlines()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#train \n",
    "fl_len = len(ts)\n",
    "cls = []\n",
    "review = []\n",
    "\n",
    "\n",
    "#test\n",
    "ts_len = len(ts1)\n",
    "t_rev = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function is for finding nearest neighbor. It takes 'k' near neighbor and get sentiment for test data \n",
    "#based on majority sentiment obtained from train data\n",
    "\n",
    "def FindNeighbor(inp_csr, K):\n",
    "    output_sentiment = []\n",
    "    for row in inp_csr:\n",
    "        #get single row from input scr matrix\n",
    "        row = np.array(row)\n",
    "        #sort and get 'k' nearest neighbor indexes\n",
    "        max_row = np.argpartition(-row, K)\n",
    "        top_rows = max_row[:K]\n",
    "        result = reviewCheck(top_rows, cls)\n",
    "        output_sentiment.append(result)\n",
    "    return output_sentiment\n",
    "\n",
    "def reviewCheck(row_index, senti_mat):\n",
    "    pos_senti = 0\n",
    "    neg_senti = 0\n",
    "    for index in row_index:\n",
    "        #check for neighbor index with corresponding sentiment\n",
    "        if senti_mat[int(index)] == \"+1\":\n",
    "            pos_senti += 1\n",
    "        else:\n",
    "            neg_senti +=1\n",
    "    #decide which would be sentiment of review \n",
    "    if pos_senti > neg_senti:\n",
    "        return \"+1\"\n",
    "    elif pos_senti < neg_senti:\n",
    "        return \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#data preprocessing for train data happens here. It removes html tags, get only alphabets, convert to lower case and \n",
    "#remove stop words \n",
    "\n",
    "for i in range(fl_len):\n",
    "    line = ts[i]\n",
    "    l_len = len(line)\n",
    "    for t in range(l_len):\n",
    "        if t ==  1:\n",
    "            cls.append(line[0:2])\n",
    "        else:\n",
    "            if t == 2:\n",
    "                text = BeautifulSoup(line[2:l_len], \"lxml\")\n",
    "                letter = re.sub(\"[^a-zA-Z]\", \" \", text.get_text())\n",
    "                l_case = letter.lower()\n",
    "                words = l_case.split()\n",
    "                #print words\n",
    "                stop = set(stopwords.words(\"english\"))\n",
    "                m_words = [wr for wr in words if not wr in stop]\n",
    "                \n",
    "                text1 = (\" \".join(m_words))\n",
    "                review.append(text1)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#data preprocessing for train data happens here. It removes html tags, get only alphabets, convert to lower case and \n",
    "#remove stop words \n",
    "\n",
    "t_rev = []\n",
    "for i in range(ts_len):\n",
    "    line = ts1[i]\n",
    "    text = BeautifulSoup(line, \"lxml\")\n",
    "    letter = re.sub(\"[^a-zA-Z]\", \" \", text.get_text())\n",
    "    l_case = letter.lower()\n",
    "    words = l_case.split()\n",
    "    stop = set(stopwords.words(\"english\"))\n",
    "    m_words = [w for w in words if not w in stop]\n",
    "    text1 = (\" \".join(m_words))\n",
    "    t_rev.append(text1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 11000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#create CSR matrix by implementing inverse document frequency and l2 normalization\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "vectorizer = TfidfVectorizer(norm = 'l2',min_df = 0, use_idf = True, smooth_idf = False, sublinear_tf = True, \\\n",
    "                             ngram_range=(1,2), max_features = 9000 )\n",
    "\n",
    "\n",
    "train_vect = vectorizer.fit_transform(review)\n",
    "\n",
    "\n",
    "train_vect = train_vect.toarray()\n",
    "print train_vect.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 11000)\n"
     ]
    }
   ],
   "source": [
    "test_vect = vectorizer.transform(t_rev)\n",
    "\n",
    "test_vect = test_vect.toarray()\n",
    "print test_vect.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get cosine similarity\n",
    "csr_sim = cosine_similarity(test_vect,train_vect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Nearest neighbor find\n",
    "\n",
    "output = FindNeighbor(csr_sim,157)\n",
    "\n",
    "with open('/home/ss/CMPE-255-Fa17/pr/format.dat', 'w') as log:\n",
    "      for x in output:\n",
    "          log.write(x+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
